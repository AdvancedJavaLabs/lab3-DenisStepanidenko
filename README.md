[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/uyodabcP)
## Лабораторная работа: Реализация MapReduce для анализа данных о продажах с ипользованием HADOOP!!!
# Цель работы

Ознакомиться с концепцией распределенных вычислений на примере модели MapReduce. Научиться разрабатывать многопоточную систему для обработки больших данных и применять её для анализа данных о продажах.
# Описание задачи

У вас в репозитории есть несколько CSV-файлов, представляющих данные о продажах, например:

    transaction_id,product_id,category,price,quantity
    1,101,electronics,300.00,2
    2,102,books,15.00,5
    3,101,electronics,300.00,1
    4,103,toys,25.00,4
    5,102,books,15.00,3

Необходимо:

  * Вычислить общую выручку для каждой категории товаров.
  * Подсчитать общее количество проданных товаров по категориям.
  * Отсортировать категории по общей выручке в порядке убывания.

Пример вывода:

    Category      Revenue    Quantity
    electronics   900.00     3
    books         120.00     8
    toys          100.00     4

# Требования
Основная часть:

  * Используем hadoop
  * Написать реализацию MapReduce для обработки CSV-файлов.
  * Реализовать многопоточность в каждой фазе:
      * Map — обработка строк из файлов.
      * Shuffle/Sort — группировка данных по категориям.
      * Reduce — вычисление итоговых значений для каждой категории.
  * Сохранить результат в файл.
  * Обеспечить потокобезопасность при работе с общими данными.
  * Реализовать поддержку одновременной обработки большого количества файлов.

Дополнительные задачи (по желанию):

* Добавить возможность выбора метрики анализа (например, подсчёт средней цены товара в категории).

# Результаты
Результатом работы является сам код, файл с результатами и экспериментальные данные по быстродействию работы написанного кода при изменении числа worker-ов / частей, на которые разбивается файл

# Архитектура решения

![Архитектура](/charts/Архитектура%20решения.png)

# Графики зависимости времени выполнения от кол-во reduce узлов для выполнения single csv файлов.

## 0.csv
![График](/charts/0_csv.png)

## 1.csv
![График](/charts/1_csv.png)

## 2.csv
![График](/charts/2_csv.png)

## 3.csv
![График](/charts/3_csv.png)

## 4.csv
![График](/charts/4_csv.png)

## 5.csv
![График](/charts/5_csv.png)

## 6.csv
![График](/charts/6_csv.png)

## 7.csv
![График](/charts/7_csv.png)

# Анализ графиков
Для каждого файла показывается сходное поведение - существует зона производительности при малом количестве reducer'ов и выраженная деградация при их увеличении.
Минимальное время выполнения практически одинаково для всех файлов, несмотря на девятикратную разницу в объёмах. Это говорит о том, что основное время тратится на расходы инициализации, а не на обработку данных.
Итого вывод можно сделать следующий - для данных менее 30MB добавление reducer'ов сверх оптимального количества приводит к ухудшению производительности из-за overhead на синхронизацию, обмен данными и управление потоками.

# Графики зависимости времени выполнения от кол-во reduce узлов при обработке всех csv файлов вместе.

![график](/charts/allCsv.png)